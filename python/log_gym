2016.8.8 gaoyimei

feature:concat_5  device_model,active_app_norm
model:gblinear
arguments:
    gblinear_alpha: l1 norm
    gblinear_lambda:l2 norm
best argument:
    l1 = 0.2
    l2 = 0.86


feature:concat_4  device_model,installed_app_norm
model:gblinear
best argument:
    alpha = 0.6
    lambda = 0.0001


feature:concat_3  phone_brand,device_model,installed_app_norm,active_app_norm
model:gblinear
best argument:
    alpha = 0.65
    lambda = 0.0001

今天的训练结果中很奇怪的一点是 不论用哪一组参数来训练 最终训练的轮数都非常少 几乎只要几轮就达到了最优情况 原因有待考证



2016.8.10 gaoyimei

training set for libsvm and liblinear must have no zero feature, which means feature index begins with 1
training set foe xgboost in my ubuntu must have same feature numbers

目前为止经历了三个阶段的训练：
1 直接使用xgboost模型 将数据集随机切分后进行训练。
    过程：手动调整参数和划分的方式
    结果：训练集采用全集 验证集采用部分集的方式效果较好
2 使用libsvm和linear模型进行训练。
    过程：修改了输入文件的格式以符合libsvm和liblinear的训练要求。 参数的调整没找到什么指导性原则，就是模仿网上的一些例子。
         另外发现libsvm的速度比较慢，训练一次要十几分钟，而liblinear则快的多。
    结果：效果并没有比直接用xgboost好
3 使用k-fold的方式和xgb模型进行训练。
    过程：寻找最优参数 包括大体的训练轮数 再使用这些参数在全集上进行训练
    结果：发现不论采用什么参数值 在concat_3 4 5 三个特征集上训练总是很快停止 原因有待发现


feature:concat_1  phone_brand,device_model,installed_app,active_app
model:gblinear
best argument:
    alpha = 0.02
    lambda = 40



2016.8.11 gaoyimei

feature:concat_6
model:gbtree
    max_depth = 3  subsample = 0.7  eta = 0.1 colsample_bytree = 0.7
    best_rounds = 786, 594, 688, 659, 740
    train_score = 2.02686818429 valid_score = 2.29690349938

    max_depth = 4  subsample = 0.7 eta = 0.1 colsample_bytree = 0.7
    best_rounds = 630, 472, 518, 575, 505
    train_score = 1.99097 valid_score = 2.29429

    max_depth = 4  subsample = 0.7 eta = 0.1 colsample_bytree = 0.8
    best_rounds = 542, 594, 585, 637, 600
    train_score = 1.95703 valid_score = 2.29412


21:33 feature files update.
Old feature files are in ./feature/feature_backup_20160811


2016.8.12 gaoyimei

feature:concat_5
model:gbtree
    colsample_bytree 0.7 影响不大 基本可以固定
    subsample 0.5-1.0
    eta 0.1-0.3
    max_depth 3-5

采用matplotlib做图分析数据:采样三维的数据 固定其中的一维 观察另外两维的变化对结果的影响

注意：使用linear模型时 因为训练过程很快就达到最优解 而linear模型输出的train_score 和 valid_score是训练停止时的得分 所以可以相应地减少
    early_stop的轮数


2016.8.13 Sat

对于ensemble中使用的feature 容易出现过拟合的现象 所以要调整参数来防止过拟合
gbtree模型中的参数种类非常多样 都要尝试一下 并且不要被参数通常的范围给限制 比如在调试ensemble_2时 subsample 和 colsample在都取0.01时
    居然取得了非常好的效果

2016.8.14 Sun

特征选择是一个非常重要的过程 将我们的得分提升到了2.26798 特别要注意的是 比赛中所使用的是真实的数据 各个特征之间是有一定的相关性的 不是简单地
    越多就越好

生成新feature的过程:
    1.feature_impl.py中编写对应的函数
        def device_weekday_event_num_freq_proc(device_id, dict_device_event):
    2.feature_factory.py中注册对应的feature
        fea_device_weekday_event_num_freq = feature.multi_feature(name='device_weekday_event_num_freq', dtype='f')
    3.feature_factory.py中的make_feature()函数中生成对应的feature文件
        fea_device_weekday_event_num_freq.process(device_id=device_id, dict_device_event=dict_device_event)
        fea_device_weekday_event_num_freq.dump()

dict_device_event中数据的格式为： [(3164698, '2016-05-06 23:47:05', 0.0, 0.0)]


2016.8.15 Mon

在面临一个新的问题时 不要还没接触就把它想得很复杂 按照过程一步一步来 遇到问题就解决问题 必须坚定地相信：办法总比困难多


2016.8.16

使用已有的pkl文件生成新的pkl文件：在stat.py文件中编写对应的函数：
    def aggregate_label_category()

2016.8.17 Wen

生成了两个新的pkl文件:
    dict_label_category_group_name.pkl: key是处理过后的label id, value是该label对应的分组的序号
    dict_label_category_group_number.pkl: key是处理过后的label id,  value是该label对应的分组的名字

注意:所有pkl文件中的device id 和app id 都是经过重新映射处理的 去除了没有在app_events中出现的app id 和没有在app_label中出现的label id


2016.8.23 Tue

训练停止时如果曲线末端呈现出抖动的状态 可以降低learning rate继续训练 但注意要逐步降低 不断优化 而不能一下子降到底


2016.9.1 Thu

在使用net2net进行训练时 以valid上的得分为标准 valid上的提升才是真正的提升
drop layer_sizes learning_rate batch_size 都是可以调的参数


